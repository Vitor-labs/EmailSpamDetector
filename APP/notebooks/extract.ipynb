{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "ytb_spam_df_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00380/YouTube-Spam-Collection-v1.zip'\n",
    "sms_spam_df_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRACTING SPAM DATA FROM UCI ARCHIVES\n",
    "\n",
    "souces:\n",
    "- youtube\n",
    "- sms \n",
    "- emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_data_by_url(url: str) -> pd.DataFrame:\n",
    "    response = requests.get(url)\n",
    "    zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "    csv_files = [file_name for file_name in zip_file.namelist() if file_name.endswith(\".csv\")]\n",
    "\n",
    "    if len(csv_files) == 1:\n",
    "        df = pd.read_csv(zip_file.open(csv_files[0]))\n",
    "\n",
    "    elif len(csv_files) == 0:\n",
    "        data_file = [file_name for file_name in zip_file.namelist() if '.' not in file_name]\n",
    "\n",
    "        if len(data_file) > 1:\n",
    "            df = pd.read_csv(zip_file.open(data_file[0]), sep='\\t', header=None)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"No CSV file found and no data file without extension found.\")\n",
    "\n",
    "    else:\n",
    "        # Multiple CSV files, concatenate them into a single DataFrame\n",
    "        csv_data = [\n",
    "            zip_file.open(file_name).read().decode(\"latin-1\")\n",
    "            for file_name in csv_files\n",
    "        ]\n",
    "\n",
    "        df = pd.concat([pd.read_csv(io.StringIO(data)) for data in csv_data])\n",
    "        del csv_data\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytb_df = get_df_data_by_url(ytb_spam_df_url)\n",
    "sms_df = get_df_data_by_url(sms_spam_df_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORMING THE DATASETS\n",
    "1. Remove unused labbels \n",
    "2. Transform categorical data to binary\n",
    "3. Join the DataSets\n",
    "4. Transform Dataframe to Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>body</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               body source\n",
       "0      0  Go until jurong point, crazy.. Available only ...    sms\n",
       "1      0                      Ok lar... Joking wif u oni...    sms\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...    sms\n",
       "3      0  U dun say so early hor... U c already then say...    sms\n",
       "4      0  Nah I don't think he goes to usf, he lives aro...    sms"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {'spam': 1, 'ham': 0}\n",
    "\n",
    "sms_df.columns = ['class', 'body']\n",
    "sms_df['source'] = 'sms'\n",
    "sms_df['class'] = sms_df['class'].replace(mapping)\n",
    "\n",
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytb_df = ytb_df.drop(columns=['COMMENT_ID', 'AUTHOR', 'DATE', 'Unnamed: 0'], axis=1)\n",
    "ytb_df = ytb_df.rename(columns={'CLASS':'class', 'CONTENT': 'body'})\n",
    "ytb_df['source'] = 'youtube'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>body</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               body source\n",
       "0    0.0  Go until jurong point, crazy.. Available only ...    sms\n",
       "1    0.0                      Ok lar... Joking wif u oni...    sms\n",
       "2    1.0  Free entry in 2 a wkly comp to win FA Cup fina...    sms\n",
       "3    0.0  U dun say so early hor... U c already then say...    sms\n",
       "4    0.0  Nah I don't think he goes to usf, he lives aro...    sms"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df = pd.concat([sms_df, ytb_df])\n",
    "spam_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conveting the labels to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " 'PRIVATE! Your 2004 Account Statement for 07742676969 shows 786 unredeemed Bonus Points. To claim call 08719180248 Identifier Code: 45239 Expires')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = spam_df['class'].tolist()\n",
    "texts = spam_df['body'].tolist()\n",
    "\n",
    "classes[120], texts[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 03:45:21.010732: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-05 03:45:21.058181: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-05 03:45:21.060182: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-05 03:45:22.172815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "MAX_NUM_WORDS = 280\n",
    "MAX_SEQ_LENGTH = 300\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH)\n",
    "y = to_categorical(np.asarray(classes))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DATASET AND METADATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split & Export Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\" Use when dataset gets bigger\n",
    "X_train, X_test, y_train, y_t2 = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "X_test, X_valid, y_train, y_test = train_test_split(X_test, y_t2, test_size=0.33, random_state=42)\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "\n",
    "BASE_DIR = pathlib.Path().resolve().parent\n",
    "EXPORT_DIR = BASE_DIR / \"exports\"\n",
    "EXPORT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "SPAM_DATASET_PATH = EXPORT_DIR / \"spam-dataset.csv\"\n",
    "\n",
    "METADATA_EXPORT_PATH = EXPORT_DIR / 'spam-metadata.pkl'\n",
    "TOKENIZER_EXPORT_PATH = EXPORT_DIR / 'spam-tokenizer.json'\n",
    "\n",
    "spam_df.to_csv(SPAM_DATASET_PATH)\n",
    "\n",
    "training_data = {\n",
    "    \"X_train\": X_train, \n",
    "    \"X_test\": X_test,\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test,\n",
    "    \"max_words\": MAX_NUM_WORDS,\n",
    "    \"max_seq_length\": MAX_SEQ_LENGTH,\n",
    "    \"label_legend\": mapping,\n",
    "}\n",
    "\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "TOKENIZER_EXPORT_PATH.write_text(tokenizer_json)\n",
    "\n",
    "with open(METADATA_EXPORT_PATH, 'wb') as f:\n",
    "    pickle.dump(training_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
