{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import pickle\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>body</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>sms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               body source\n",
       "0    0.0  Go until jurong point, crazy.. Available only ...    sms\n",
       "1    0.0                      Ok lar... Joking wif u oni...    sms\n",
       "2    1.0  Free entry in 2 a wkly comp to win FA Cup fina...    sms\n",
       "3    0.0  U dun say so early hor... U c already then say...    sms\n",
       "4    0.0  Nah I don't think he goes to usf, he lives aro...    sms"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = pathlib.Path().resolve().parent\n",
    "EXPORT_DIR = BASE_DIR / \"exports\"\n",
    "\n",
    "SPAM_DATASET_PATH = EXPORT_DIR / \"spam-dataset.csv\"\n",
    "METADATA_EXPORT_PATH = EXPORT_DIR / 'spam-metadata.pkl'\n",
    "TOKENIZER_EXPORT_PATH = EXPORT_DIR / 'spam-tokenizer.json'\n",
    "\n",
    "with open(TOKENIZER_EXPORT_PATH, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    tokens = json.dumps(data)\n",
    "    tokenizer = tokenizer_from_json(tokens)\n",
    "\n",
    "df = pd.read_csv(SPAM_DATASET_PATH, index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(METADATA_EXPORT_PATH, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_test = data['X_test']\n",
    "X_train = data['X_train']\n",
    "y_test = data['y_test']\n",
    "y_train = data['y_train']\n",
    "legend = data['label_legend']\n",
    "max_sequence = data['max_seq_length']\n",
    "max_words = data['max_words']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 128)          35840     \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 300, 128)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 196)               254800    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 394       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291,034\n",
      "Trainable params: 291,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_words, embed_dim, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(2, activation='softmax')) # remenber: SoftMax return is on % \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 242s 1s/step - loss: 0.2650 - accuracy: 0.8986 - val_loss: 0.1340 - val_accuracy: 0.9575\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 210s 1s/step - loss: 0.1352 - accuracy: 0.9569 - val_loss: 0.1276 - val_accuracy: 0.9558\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 207s 1s/step - loss: 0.1258 - accuracy: 0.9592 - val_loss: 0.1353 - val_accuracy: 0.9575\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 219s 1s/step - loss: 0.1195 - accuracy: 0.9612 - val_loss: 0.1201 - val_accuracy: 0.9602\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 208s 1s/step - loss: 0.1131 - accuracy: 0.9656 - val_loss: 0.1203 - val_accuracy: 0.9575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f490512bb50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, verbose=1, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_EXPORT_PATH = EXPORT_DIR / 'spam-model.h5'\n",
    "model.save(str(MODEL_EXPORT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 177ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'han': 0.9797849, 'spam': 0.020215118}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(text_str, max_words=280, max_sequence = 280, tokenizer=None):\n",
    "    if not tokenizer: return None\n",
    "    \n",
    "    sequences = tokenizer.texts_to_sequences([text_str])\n",
    "    \n",
    "    x_input = pad_sequences(sequences, maxlen=max_sequence)\n",
    "    y_output = model.predict(x_input)\n",
    "    \n",
    "    top_y_index = np.argmax(y_output)\n",
    "    preds = y_output[top_y_index]\n",
    "\n",
    "    result = {'han': preds[0], 'spam': preds[1]}\n",
    "    return result\n",
    "\n",
    "predict(\"Hello world\", max_words=max_words, max_sequence=max_sequence, tokenizer=tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EmailSpamDetector-FLb_7-OX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
